{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8194151,"sourceType":"datasetVersion","datasetId":4853242},{"sourceId":8194132,"sourceType":"datasetVersion","datasetId":4853226},{"sourceId":8226033,"sourceType":"datasetVersion","datasetId":4877536}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load the arguments data (assuming it has columns 'id', 'premise')\narguments_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/arguments-training.tsv', delimiter='\\t')\n\n# Load the value labels data (assuming it has columns 'id', 'value_label')\nlabels_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/labels-training.tsv', delimiter='\\t')\n\n# Load the value descriptions from a JSON file\nwith open('/kaggle/input/value-categories-2/value-categories.json', 'r') as file:\n    value_descriptions = json.load(file)\n\nlabels_long_df = labels_df.melt(id_vars='Argument ID', var_name='value_category', value_name='label')\nlabels_long_df['label'] = labels_long_df['label'].replace({0: 2, 1: 0})\n# labels_long_df = labels_long_df[labels_long_df['value_category'] != 'Universalism: objectivity']\nlabels_long_df['value_description'] = labels_long_df['value_category'].apply(lambda x: value_descriptions[x.lower().replace(\": \",\"-\")]['personal-motivation'])\ncombined_df = pd.merge(arguments_df, labels_long_df, left_on='Argument ID', right_on='Argument ID')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T11:56:49.581308Z","iopub.execute_input":"2024-04-25T11:56:49.581664Z","iopub.status.idle":"2024-04-25T11:56:49.742298Z","shell.execute_reply.started":"2024-04-25T11:56:49.581636Z","shell.execute_reply":"2024-04-25T11:56:49.741448Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"labels_long_df","metadata":{"execution":{"iopub.status.busy":"2024-04-25T11:56:53.513857Z","iopub.execute_input":"2024-04-25T11:56:53.514984Z","iopub.status.idle":"2024-04-25T11:56:53.526420Z","shell.execute_reply.started":"2024-04-25T11:56:53.514951Z","shell.execute_reply":"2024-04-25T11:56:53.525510Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"       Argument ID             value_category  label  \\\n0           A01002    Self-direction: thought      2   \n1           A01005    Self-direction: thought      2   \n2           A01006    Self-direction: thought      2   \n3           A01007    Self-direction: thought      2   \n4           A01008    Self-direction: thought      2   \n...            ...                        ...    ...   \n107855      E08016  Universalism: objectivity      2   \n107856      E08017  Universalism: objectivity      0   \n107857      E08018  Universalism: objectivity      2   \n107858      E08019  Universalism: objectivity      0   \n107859      E08020  Universalism: objectivity      2   \n\n                                        value_description  \n0       It is important to be creative, forming own op...  \n1       It is important to be creative, forming own op...  \n2       It is important to be creative, forming own op...  \n3       It is important to be creative, forming own op...  \n4       It is important to be creative, forming own op...  \n...                                                   ...  \n107855  Having a better hold on numbers, relying on sc...  \n107856  Having a better hold on numbers, relying on sc...  \n107857  Having a better hold on numbers, relying on sc...  \n107858  Having a better hold on numbers, relying on sc...  \n107859  Having a better hold on numbers, relying on sc...  \n\n[107860 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Argument ID</th>\n      <th>value_category</th>\n      <th>label</th>\n      <th>value_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A01002</td>\n      <td>Self-direction: thought</td>\n      <td>2</td>\n      <td>It is important to be creative, forming own op...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A01005</td>\n      <td>Self-direction: thought</td>\n      <td>2</td>\n      <td>It is important to be creative, forming own op...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A01006</td>\n      <td>Self-direction: thought</td>\n      <td>2</td>\n      <td>It is important to be creative, forming own op...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A01007</td>\n      <td>Self-direction: thought</td>\n      <td>2</td>\n      <td>It is important to be creative, forming own op...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A01008</td>\n      <td>Self-direction: thought</td>\n      <td>2</td>\n      <td>It is important to be creative, forming own op...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>107855</th>\n      <td>E08016</td>\n      <td>Universalism: objectivity</td>\n      <td>2</td>\n      <td>Having a better hold on numbers, relying on sc...</td>\n    </tr>\n    <tr>\n      <th>107856</th>\n      <td>E08017</td>\n      <td>Universalism: objectivity</td>\n      <td>0</td>\n      <td>Having a better hold on numbers, relying on sc...</td>\n    </tr>\n    <tr>\n      <th>107857</th>\n      <td>E08018</td>\n      <td>Universalism: objectivity</td>\n      <td>2</td>\n      <td>Having a better hold on numbers, relying on sc...</td>\n    </tr>\n    <tr>\n      <th>107858</th>\n      <td>E08019</td>\n      <td>Universalism: objectivity</td>\n      <td>0</td>\n      <td>Having a better hold on numbers, relying on sc...</td>\n    </tr>\n    <tr>\n      <th>107859</th>\n      <td>E08020</td>\n      <td>Universalism: objectivity</td>\n      <td>2</td>\n      <td>Having a better hold on numbers, relying on sc...</td>\n    </tr>\n  </tbody>\n</table>\n<p>107860 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"final_df=combined_df\ndf_majority = final_df[final_df.label == 2]\ndf_minority = final_df[final_df.label == 0]\n\n# Determine the number of instances you want to keep from the majority class\n# For example, you might want to have a 1:1 ratio\nnumber_of_instances = len(df_minority)\n\n# Downsample the majority class\ndf_majority_downsampled = df_majority.sample(n=number_of_instances)\n\n# Combine the downsampled majority class with the minority class to get a balanced dataset\nbalanced_df = pd.concat([df_majority_downsampled, df_minority])\n\n# Shuffle the dataset to mix the two classes well\nbalanced_df = balanced_df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T11:56:55.876370Z","iopub.execute_input":"2024-04-25T11:56:55.877226Z","iopub.status.idle":"2024-04-25T11:56:55.916593Z","shell.execute_reply.started":"2024-04-25T11:56:55.877194Z","shell.execute_reply":"2024-04-25T11:56:55.915827Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset, random_split\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom torch.nn.functional import cross_entropy\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer,AutoConfig\nimport torch\nfrom sklearn.metrics import accuracy_score\nmodel_name = 'pepa/roberta-base-snli'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel=model.to(device)\ninputs = tokenizer(list(balanced_df['Premise']), list(balanced_df['value_description']), padding=True, truncation=True, return_tensors=\"pt\")\ninput_ids = inputs['input_ids']\nattention_mask = inputs['attention_mask']\nlabels = torch.tensor(balanced_df['label'].values)\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T11:56:58.263183Z","iopub.execute_input":"2024-04-25T11:56:58.263771Z","iopub.status.idle":"2024-04-25T11:57:14.691637Z","shell.execute_reply.started":"2024-04-25T11:56:58.263735Z","shell.execute_reply":"2024-04-25T11:57:14.690507Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"tensor([2, 0, 0,  ..., 2, 2, 2])\n","output_type":"stream"}]},{"cell_type":"code","source":"balanced_df","metadata":{"execution":{"iopub.status.busy":"2024-04-25T11:57:17.898170Z","iopub.execute_input":"2024-04-25T11:57:17.898537Z","iopub.status.idle":"2024-04-25T11:57:17.914426Z","shell.execute_reply.started":"2024-04-25T11:57:17.898507Z","shell.execute_reply":"2024-04-25T11:57:17.913501Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"      Argument ID                                         Conclusion  \\\n0          A27196   We should subsidize embryonic stem cell research   \n1          A24307                     We should cancel pride parades   \n2          A30210                   We should prohibit school prayer   \n3          E07080  We need an inclusive and pluralistic European ...   \n4          A12065  We should stop the development of autonomous cars   \n...           ...                                                ...   \n36735      A18328                     We should subsidize journalism   \n36736      A25289                   We should prohibit school prayer   \n36737      A28324  We should adopt a zero-tolerance policy in sch...   \n36738      A29347              We should introduce compulsory voting   \n36739      A12300                              We should ban whaling   \n\n            Stance                                            Premise  \\\n0          against  we should not subsidize embryonic stem cell re...   \n1          against  they shouldnt be banned, it's just people comi...   \n2          against  school prayer adds structure to a students lif...   \n3          against  Europe is full and cannot accept more illegal ...   \n4      in favor of      they can be more dangerous than human drivers   \n...            ...                                                ...   \n36735  in favor of  keeping journalist in work helps the nation ke...   \n36736      against       every religious person has the right to pray   \n36737      against  a zero-tolerance policy in schools shouldn't b...   \n36738      against  the penalties on not voting would bring backla...   \n36739      against  most whaling is done under controlled situatio...   \n\n               value_category  label  \\\n0                 Stimulation      2   \n1       Universalism: concern      0   \n2                   Tradition      0   \n3      Self-direction: action      2   \n4                        Face      2   \n...                       ...    ...   \n36735    Universalism: nature      2   \n36736             Achievement      2   \n36737             Stimulation      2   \n36738        Power: dominance      2   \n36739        Power: resources      2   \n\n                                       value_description  \n0      Always looking for something new to do, doing ...  \n1      Protecting the weak and vulnerable, care about...  \n2      Maintain traditional beliefs and values, follo...  \n3      It is important to make own decisions about li...  \n4      Does not want to be shamed by others, protecti...  \n...                                                  ...  \n36735  Care about nature for nature's sake, protect t...  \n36736  Being ambitious, successful and being admired ...  \n36737  Always looking for something new to do, doing ...  \n36738  Want people to follow you, being the most infl...  \n36739  Having lots of money for the power it brings, ...  \n\n[36740 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Argument ID</th>\n      <th>Conclusion</th>\n      <th>Stance</th>\n      <th>Premise</th>\n      <th>value_category</th>\n      <th>label</th>\n      <th>value_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A27196</td>\n      <td>We should subsidize embryonic stem cell research</td>\n      <td>against</td>\n      <td>we should not subsidize embryonic stem cell re...</td>\n      <td>Stimulation</td>\n      <td>2</td>\n      <td>Always looking for something new to do, doing ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A24307</td>\n      <td>We should cancel pride parades</td>\n      <td>against</td>\n      <td>they shouldnt be banned, it's just people comi...</td>\n      <td>Universalism: concern</td>\n      <td>0</td>\n      <td>Protecting the weak and vulnerable, care about...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A30210</td>\n      <td>We should prohibit school prayer</td>\n      <td>against</td>\n      <td>school prayer adds structure to a students lif...</td>\n      <td>Tradition</td>\n      <td>0</td>\n      <td>Maintain traditional beliefs and values, follo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E07080</td>\n      <td>We need an inclusive and pluralistic European ...</td>\n      <td>against</td>\n      <td>Europe is full and cannot accept more illegal ...</td>\n      <td>Self-direction: action</td>\n      <td>2</td>\n      <td>It is important to make own decisions about li...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A12065</td>\n      <td>We should stop the development of autonomous cars</td>\n      <td>in favor of</td>\n      <td>they can be more dangerous than human drivers</td>\n      <td>Face</td>\n      <td>2</td>\n      <td>Does not want to be shamed by others, protecti...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36735</th>\n      <td>A18328</td>\n      <td>We should subsidize journalism</td>\n      <td>in favor of</td>\n      <td>keeping journalist in work helps the nation ke...</td>\n      <td>Universalism: nature</td>\n      <td>2</td>\n      <td>Care about nature for nature's sake, protect t...</td>\n    </tr>\n    <tr>\n      <th>36736</th>\n      <td>A25289</td>\n      <td>We should prohibit school prayer</td>\n      <td>against</td>\n      <td>every religious person has the right to pray</td>\n      <td>Achievement</td>\n      <td>2</td>\n      <td>Being ambitious, successful and being admired ...</td>\n    </tr>\n    <tr>\n      <th>36737</th>\n      <td>A28324</td>\n      <td>We should adopt a zero-tolerance policy in sch...</td>\n      <td>against</td>\n      <td>a zero-tolerance policy in schools shouldn't b...</td>\n      <td>Stimulation</td>\n      <td>2</td>\n      <td>Always looking for something new to do, doing ...</td>\n    </tr>\n    <tr>\n      <th>36738</th>\n      <td>A29347</td>\n      <td>We should introduce compulsory voting</td>\n      <td>against</td>\n      <td>the penalties on not voting would bring backla...</td>\n      <td>Power: dominance</td>\n      <td>2</td>\n      <td>Want people to follow you, being the most infl...</td>\n    </tr>\n    <tr>\n      <th>36739</th>\n      <td>A12300</td>\n      <td>We should ban whaling</td>\n      <td>against</td>\n      <td>most whaling is done under controlled situatio...</td>\n      <td>Power: resources</td>\n      <td>2</td>\n      <td>Having lots of money for the power it brings, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>36740 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AdamW, get_linear_schedule_with_warmup, AutoModelForSequenceClassification, AutoTokenizer\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\n# Define contrastive loss function\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n        contrastive_loss = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n                                      label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return contrastive_loss\n\n# Load the data\n\n# Load tokenizer and model\nmodel_name = 'pepa/roberta-base-snli'  # Assuming you're using RoBERTa\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Tokenize input data\ninputs = tokenizer(list(balanced_df['Premise']), list(balanced_df['value_description']),\n                   padding=True, truncation=True, return_tensors=\"pt\")\ninput_ids = inputs['input_ids']\nattention_mask = inputs['attention_mask']\nlabels = torch.tensor(balanced_df['label'].values)\n\n# Create dataset and dataloader\ntrain_dataset = TensorDataset(input_ids, attention_mask, labels)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n\n# Define optimizer and scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5)\nepochs = 3\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n# Define a training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    steps = 0\n\n    for batch in train_dataloader:\n        b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]\n        \n        optimizer.zero_grad()\n        \n        # Forward pass through RoBERTa base model\n        outputs = model(input_ids=b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n        logits = outputs.logits\n        \n        # Calculate classification loss\n        classification_loss = outputs.loss\n        \n        # Generate contrastive learning targets\n        with torch.no_grad():\n            shuffled_indices = torch.randperm(b_input_ids.size(0))\n            shuffled_input_ids = b_input_ids[shuffled_indices]\n            shuffled_attention_mask = b_attention_mask[shuffled_indices]\n        \n        # Forward pass through RoBERTa base model with shuffled inputs\n        shuffled_outputs = model(input_ids=shuffled_input_ids, attention_mask=shuffled_attention_mask)\n        shuffled_logits = shuffled_outputs.logits\n        \n        # Calculate contrastive loss\n        contrastive_criterion = ContrastiveLoss()\n        contrastive_loss = contrastive_criterion(logits, shuffled_logits, label=torch.ones_like(logits[:, 0]))\n        \n        # Total combined loss\n        combined_loss = classification_loss + contrastive_loss\n\n        combined_loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += combined_loss.item()\n        steps += 1\n\n        if steps % 200 == 0:\n            print(f\"Epoch {epoch + 1}, Step {steps}, Loss: {total_loss / steps:.4f}\")\n\nprint(\"Training complete\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T12:26:14.934531Z","iopub.execute_input":"2024-04-25T12:26:14.935418Z","iopub.status.idle":"2024-04-25T13:44:46.074655Z","shell.execute_reply.started":"2024-04-25T12:26:14.935384Z","shell.execute_reply":"2024-04-25T13:44:46.073708Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Step 200, Loss: 0.8288\nEpoch 1, Step 400, Loss: 0.7563\nEpoch 1, Step 600, Loss: 0.7235\nEpoch 1, Step 800, Loss: 0.7022\nEpoch 1, Step 1000, Loss: 0.6867\nEpoch 1, Step 1200, Loss: 0.6695\nEpoch 1, Step 1400, Loss: 0.6576\nEpoch 1, Step 1600, Loss: 0.6474\nEpoch 1, Step 1800, Loss: 0.6371\nEpoch 1, Step 2000, Loss: 0.6309\nEpoch 1, Step 2200, Loss: 0.6244\nEpoch 1, Step 2400, Loss: 0.6193\nEpoch 1, Step 2600, Loss: 0.6134\nEpoch 1, Step 2800, Loss: 0.6081\nEpoch 1, Step 3000, Loss: 0.6047\nEpoch 1, Step 3200, Loss: 0.5996\nEpoch 1, Step 3400, Loss: 0.5948\nEpoch 1, Step 3600, Loss: 0.5905\nEpoch 1, Step 3800, Loss: 0.5874\nEpoch 1, Step 4000, Loss: 0.5834\nEpoch 1, Step 4200, Loss: 0.5801\nEpoch 1, Step 4400, Loss: 0.5773\nTraining complete\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the file path to save the model\nmodel_path = \"contrastive_entailment_model.pth\"\n\n# Save the model state dictionary\ntorch.save(model, model_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:44:58.223098Z","iopub.execute_input":"2024-04-25T13:44:58.223452Z","iopub.status.idle":"2024-04-25T13:44:59.322160Z","shell.execute_reply.started":"2024-04-25T13:44:58.223423Z","shell.execute_reply":"2024-04-25T13:44:59.321137Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load the arguments data (assuming it has columns 'id', 'premise')\narguments_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/arguments-validation.tsv', delimiter='\\t')\n\n# Load the value labels data (assuming it has columns 'id', 'value_label')\nlabels_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/labels-validation.tsv', delimiter='\\t')\n\n# Load the value descriptions from a JSON file\nwith open('/kaggle/input/value-categories-2/value-categories.json', 'r') as file:\n    value_descriptions = json.load(file)\n    \nlabels_long_df = labels_df.melt(id_vars='Argument ID', var_name='value_category', value_name='label')\nlabels_long_df['label'] = labels_long_df['label'].replace({0: 2, 1: 0})\n# labels_long_df = labels_long_df[labels_long_df['value_category'] != 'Universalism: objectivity']\nlabels_long_df['value_description'] = labels_long_df['value_category'].apply(lambda x: value_descriptions[x.lower().replace(\": \",\"-\")]['personal-motivation'])\ncombined_df_val = pd.merge(arguments_df, labels_long_df, left_on='Argument ID', right_on='Argument ID')\ncombined_df_val['Argument'] = combined_df_val.apply(\n    lambda row: f\"{row['Stance']} {row['Conclusion']} by saying {row['Premise']}\",\n    axis=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:45:03.078731Z","iopub.execute_input":"2024-04-25T13:45:03.079494Z","iopub.status.idle":"2024-04-25T13:45:03.886668Z","shell.execute_reply.started":"2024-04-25T13:45:03.079459Z","shell.execute_reply":"2024-04-25T13:45:03.885865Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"test_inputs = tokenizer(list(combined_df_val['Argument']), list(combined_df_val['value_description']), padding=True, truncation=True, return_tensors=\"pt\")\ntest_input_ids = test_inputs['input_ids'].to(device)\ntest_attention_mask = test_inputs['attention_mask'].to(device)\ntest_labels = torch.tensor(combined_df_val['label'].values).to(device)\n\ntest_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\ntest_dataloader = DataLoader(test_dataset, batch_size=16)\n\n# Function to evaluate the model on the test set\ndef evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [b.to(device) for b in batch]\n\n            outputs = model(b_input_ids, attention_mask=b_attention_mask)\n            logits = outputs.logits\n\n            logits = logits.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n\n            batch_predictions = np.argmax(logits, axis=1)\n            predictions.extend(batch_predictions)\n            true_labels.extend(label_ids)\n\n    return predictions, true_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:45:07.372221Z","iopub.execute_input":"2024-04-25T13:45:07.372918Z","iopub.status.idle":"2024-04-25T13:45:24.192825Z","shell.execute_reply.started":"2024-04-25T13:45:07.372888Z","shell.execute_reply":"2024-04-25T13:45:24.191980Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset,DataLoader\nmodel=model.to(device)\nclass CategoryDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=512):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data.iloc[idx]\n        premise = item['Argument']\n        description = item['value_description']\n        label = item['label']\n        category = item['value_category']\n        \n        # Tokenize the text pair\n        encoding = self.tokenizer(premise, description, add_special_tokens=True, \n                                  max_length=self.max_len, padding='max_length', \n                                  truncation=True, return_tensors=\"pt\")\n        \n        input_ids = encoding['input_ids'].squeeze(0)  # Remove the batch dimension\n        attention_mask = encoding['attention_mask'].squeeze(0)\n        \n        return input_ids, attention_mask, torch.tensor(label, dtype=torch.float), category\n    \ndataset = CategoryDataset(combined_df_val,tokenizer)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n\ndef evaluate_model(model, dataloader, device):\n    model.eval()\n    all_logits = []\n    all_labels = []\n    all_categories = []\n    all_predictions = []\n    print(len(dataloader))\n\n    with torch.no_grad():\n        for (j,(input_ids, attention_mask, labels, categories)) in enumerate(dataloader):\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n\n            # Calculate probabilities using softmax for multi-class\n            probabilities = torch.softmax(logits, dim=1)\n            predictions = torch.argmax(probabilities, dim=1)  # Initial predictions\n\n            # Adjust predictions where class '1' should be ignored\n            for i, pred in enumerate(predictions):\n                if pred == 1:\n                    # Get probabilities for classes 0 and 2\n                    prob_0 = probabilities[i, 0]\n                    prob_2 = probabilities[i, 2]\n                    # Choose the class (either 0 or 2) with the highest probability excluding class 1\n                    predictions[i] = 0 if prob_0 > prob_2 else 2\n\n            # Store the results\n            all_logits.append(logits.cpu())\n            all_labels.append(labels.cpu())\n            all_predictions.append(predictions.cpu())\n            all_categories.append(categories)  # Assuming categories can be batched directly\n            print(j)\n\n    # Concatenate results from all batches\n    all_logits = torch.cat(all_logits).numpy()\n    all_labels = torch.cat(all_labels).numpy()\n    all_predictions = torch.cat(all_predictions).numpy()\n    all_categories = np.concatenate(all_categories)\n\n    return all_logits, all_labels, all_predictions, all_categories\n\n# Assuming model, dataloader, and device are defined and properly setup\nlogits, labels, predictions, categories = evaluate_model(model, dataloader, device)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:55:10.434609Z","iopub.execute_input":"2024-04-25T13:55:10.435271Z","iopub.status.idle":"2024-04-25T14:13:57.137325Z","shell.execute_reply.started":"2024-04-25T13:55:10.435238Z","shell.execute_reply":"2024-04-25T14:13:57.136411Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"1\n2370\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n300\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\n400\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\n500\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\n600\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\n700\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\n800\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\n832\n833\n834\n835\n836\n837\n838\n839\n840\n841\n842\n843\n844\n845\n846\n847\n848\n849\n850\n851\n852\n853\n854\n855\n856\n857\n858\n859\n860\n861\n862\n863\n864\n865\n866\n867\n868\n869\n870\n871\n872\n873\n874\n875\n876\n877\n878\n879\n880\n881\n882\n883\n884\n885\n886\n887\n888\n889\n890\n891\n892\n893\n894\n895\n896\n897\n898\n899\n900\n901\n902\n903\n904\n905\n906\n907\n908\n909\n910\n911\n912\n913\n914\n915\n916\n917\n918\n919\n920\n921\n922\n923\n924\n925\n926\n927\n928\n929\n930\n931\n932\n933\n934\n935\n936\n937\n938\n939\n940\n941\n942\n943\n944\n945\n946\n947\n948\n949\n950\n951\n952\n953\n954\n955\n956\n957\n958\n959\n960\n961\n962\n963\n964\n965\n966\n967\n968\n969\n970\n971\n972\n973\n974\n975\n976\n977\n978\n979\n980\n981\n982\n983\n984\n985\n986\n987\n988\n989\n990\n991\n992\n993\n994\n995\n996\n997\n998\n999\n1000\n1001\n1002\n1003\n1004\n1005\n1006\n1007\n1008\n1009\n1010\n1011\n1012\n1013\n1014\n1015\n1016\n1017\n1018\n1019\n1020\n1021\n1022\n1023\n1024\n1025\n1026\n1027\n1028\n1029\n1030\n1031\n1032\n1033\n1034\n1035\n1036\n1037\n1038\n1039\n1040\n1041\n1042\n1043\n1044\n1045\n1046\n1047\n1048\n1049\n1050\n1051\n1052\n1053\n1054\n1055\n1056\n1057\n1058\n1059\n1060\n1061\n1062\n1063\n1064\n1065\n1066\n1067\n1068\n1069\n1070\n1071\n1072\n1073\n1074\n1075\n1076\n1077\n1078\n1079\n1080\n1081\n1082\n1083\n1084\n1085\n1086\n1087\n1088\n1089\n1090\n1091\n1092\n1093\n1094\n1095\n1096\n1097\n1098\n1099\n1100\n1101\n1102\n1103\n1104\n1105\n1106\n1107\n1108\n1109\n1110\n1111\n1112\n1113\n1114\n1115\n1116\n1117\n1118\n1119\n1120\n1121\n1122\n1123\n1124\n1125\n1126\n1127\n1128\n1129\n1130\n1131\n1132\n1133\n1134\n1135\n1136\n1137\n1138\n1139\n1140\n1141\n1142\n1143\n1144\n1145\n1146\n1147\n1148\n1149\n1150\n1151\n1152\n1153\n1154\n1155\n1156\n1157\n1158\n1159\n1160\n1161\n1162\n1163\n1164\n1165\n1166\n1167\n1168\n1169\n1170\n1171\n1172\n1173\n1174\n1175\n1176\n1177\n1178\n1179\n1180\n1181\n1182\n1183\n1184\n1185\n1186\n1187\n1188\n1189\n1190\n1191\n1192\n1193\n1194\n1195\n1196\n1197\n1198\n1199\n1200\n1201\n1202\n1203\n1204\n1205\n1206\n1207\n1208\n1209\n1210\n1211\n1212\n1213\n1214\n1215\n1216\n1217\n1218\n1219\n1220\n1221\n1222\n1223\n1224\n1225\n1226\n1227\n1228\n1229\n1230\n1231\n1232\n1233\n1234\n1235\n1236\n1237\n1238\n1239\n1240\n1241\n1242\n1243\n1244\n1245\n1246\n1247\n1248\n1249\n1250\n1251\n1252\n1253\n1254\n1255\n1256\n1257\n1258\n1259\n1260\n1261\n1262\n1263\n1264\n1265\n1266\n1267\n1268\n1269\n1270\n1271\n1272\n1273\n1274\n1275\n1276\n1277\n1278\n1279\n1280\n1281\n1282\n1283\n1284\n1285\n1286\n1287\n1288\n1289\n1290\n1291\n1292\n1293\n1294\n1295\n1296\n1297\n1298\n1299\n1300\n1301\n1302\n1303\n1304\n1305\n1306\n1307\n1308\n1309\n1310\n1311\n1312\n1313\n1314\n1315\n1316\n1317\n1318\n1319\n1320\n1321\n1322\n1323\n1324\n1325\n1326\n1327\n1328\n1329\n1330\n1331\n1332\n1333\n1334\n1335\n1336\n1337\n1338\n1339\n1340\n1341\n1342\n1343\n1344\n1345\n1346\n1347\n1348\n1349\n1350\n1351\n1352\n1353\n1354\n1355\n1356\n1357\n1358\n1359\n1360\n1361\n1362\n1363\n1364\n1365\n1366\n1367\n1368\n1369\n1370\n1371\n1372\n1373\n1374\n1375\n1376\n1377\n1378\n1379\n1380\n1381\n1382\n1383\n1384\n1385\n1386\n1387\n1388\n1389\n1390\n1391\n1392\n1393\n1394\n1395\n1396\n1397\n1398\n1399\n1400\n1401\n1402\n1403\n1404\n1405\n1406\n1407\n1408\n1409\n1410\n1411\n1412\n1413\n1414\n1415\n1416\n1417\n1418\n1419\n1420\n1421\n1422\n1423\n1424\n1425\n1426\n1427\n1428\n1429\n1430\n1431\n1432\n1433\n1434\n1435\n1436\n1437\n1438\n1439\n1440\n1441\n1442\n1443\n1444\n1445\n1446\n1447\n1448\n1449\n1450\n1451\n1452\n1453\n1454\n1455\n1456\n1457\n1458\n1459\n1460\n1461\n1462\n1463\n1464\n1465\n1466\n1467\n1468\n1469\n1470\n1471\n1472\n1473\n1474\n1475\n1476\n1477\n1478\n1479\n1480\n1481\n1482\n1483\n1484\n1485\n1486\n1487\n1488\n1489\n1490\n1491\n1492\n1493\n1494\n1495\n1496\n1497\n1498\n1499\n1500\n1501\n1502\n1503\n1504\n1505\n1506\n1507\n1508\n1509\n1510\n1511\n1512\n1513\n1514\n1515\n1516\n1517\n1518\n1519\n1520\n1521\n1522\n1523\n1524\n1525\n1526\n1527\n1528\n1529\n1530\n1531\n1532\n1533\n1534\n1535\n1536\n1537\n1538\n1539\n1540\n1541\n1542\n1543\n1544\n1545\n1546\n1547\n1548\n1549\n1550\n1551\n1552\n1553\n1554\n1555\n1556\n1557\n1558\n1559\n1560\n1561\n1562\n1563\n1564\n1565\n1566\n1567\n1568\n1569\n1570\n1571\n1572\n1573\n1574\n1575\n1576\n1577\n1578\n1579\n1580\n1581\n1582\n1583\n1584\n1585\n1586\n1587\n1588\n1589\n1590\n1591\n1592\n1593\n1594\n1595\n1596\n1597\n1598\n1599\n1600\n1601\n1602\n1603\n1604\n1605\n1606\n1607\n1608\n1609\n1610\n1611\n1612\n1613\n1614\n1615\n1616\n1617\n1618\n1619\n1620\n1621\n1622\n1623\n1624\n1625\n1626\n1627\n1628\n1629\n1630\n1631\n1632\n1633\n1634\n1635\n1636\n1637\n1638\n1639\n1640\n1641\n1642\n1643\n1644\n1645\n1646\n1647\n1648\n1649\n1650\n1651\n1652\n1653\n1654\n1655\n1656\n1657\n1658\n1659\n1660\n1661\n1662\n1663\n1664\n1665\n1666\n1667\n1668\n1669\n1670\n1671\n1672\n1673\n1674\n1675\n1676\n1677\n1678\n1679\n1680\n1681\n1682\n1683\n1684\n1685\n1686\n1687\n1688\n1689\n1690\n1691\n1692\n1693\n1694\n1695\n1696\n1697\n1698\n1699\n1700\n1701\n1702\n1703\n1704\n1705\n1706\n1707\n1708\n1709\n1710\n1711\n1712\n1713\n1714\n1715\n1716\n1717\n1718\n1719\n1720\n1721\n1722\n1723\n1724\n1725\n1726\n1727\n1728\n1729\n1730\n1731\n1732\n1733\n1734\n1735\n1736\n1737\n1738\n1739\n1740\n1741\n1742\n1743\n1744\n1745\n1746\n1747\n1748\n1749\n1750\n1751\n1752\n1753\n1754\n1755\n1756\n1757\n1758\n1759\n1760\n1761\n1762\n1763\n1764\n1765\n1766\n1767\n1768\n1769\n1770\n1771\n1772\n1773\n1774\n1775\n1776\n1777\n1778\n1779\n1780\n1781\n1782\n1783\n1784\n1785\n1786\n1787\n1788\n1789\n1790\n1791\n1792\n1793\n1794\n1795\n1796\n1797\n1798\n1799\n1800\n1801\n1802\n1803\n1804\n1805\n1806\n1807\n1808\n1809\n1810\n1811\n1812\n1813\n1814\n1815\n1816\n1817\n1818\n1819\n1820\n1821\n1822\n1823\n1824\n1825\n1826\n1827\n1828\n1829\n1830\n1831\n1832\n1833\n1834\n1835\n1836\n1837\n1838\n1839\n1840\n1841\n1842\n1843\n1844\n1845\n1846\n1847\n1848\n1849\n1850\n1851\n1852\n1853\n1854\n1855\n1856\n1857\n1858\n1859\n1860\n1861\n1862\n1863\n1864\n1865\n1866\n1867\n1868\n1869\n1870\n1871\n1872\n1873\n1874\n1875\n1876\n1877\n1878\n1879\n1880\n1881\n1882\n1883\n1884\n1885\n1886\n1887\n1888\n1889\n1890\n1891\n1892\n1893\n1894\n1895\n1896\n1897\n1898\n1899\n1900\n1901\n1902\n1903\n1904\n1905\n1906\n1907\n1908\n1909\n1910\n1911\n1912\n1913\n1914\n1915\n1916\n1917\n1918\n1919\n1920\n1921\n1922\n1923\n1924\n1925\n1926\n1927\n1928\n1929\n1930\n1931\n1932\n1933\n1934\n1935\n1936\n1937\n1938\n1939\n1940\n1941\n1942\n1943\n1944\n1945\n1946\n1947\n1948\n1949\n1950\n1951\n1952\n1953\n1954\n1955\n1956\n1957\n1958\n1959\n1960\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n2025\n2026\n2027\n2028\n2029\n2030\n2031\n2032\n2033\n2034\n2035\n2036\n2037\n2038\n2039\n2040\n2041\n2042\n2043\n2044\n2045\n2046\n2047\n2048\n2049\n2050\n2051\n2052\n2053\n2054\n2055\n2056\n2057\n2058\n2059\n2060\n2061\n2062\n2063\n2064\n2065\n2066\n2067\n2068\n2069\n2070\n2071\n2072\n2073\n2074\n2075\n2076\n2077\n2078\n2079\n2080\n2081\n2082\n2083\n2084\n2085\n2086\n2087\n2088\n2089\n2090\n2091\n2092\n2093\n2094\n2095\n2096\n2097\n2098\n2099\n2100\n2101\n2102\n2103\n2104\n2105\n2106\n2107\n2108\n2109\n2110\n2111\n2112\n2113\n2114\n2115\n2116\n2117\n2118\n2119\n2120\n2121\n2122\n2123\n2124\n2125\n2126\n2127\n2128\n2129\n2130\n2131\n2132\n2133\n2134\n2135\n2136\n2137\n2138\n2139\n2140\n2141\n2142\n2143\n2144\n2145\n2146\n2147\n2148\n2149\n2150\n2151\n2152\n2153\n2154\n2155\n2156\n2157\n2158\n2159\n2160\n2161\n2162\n2163\n2164\n2165\n2166\n2167\n2168\n2169\n2170\n2171\n2172\n2173\n2174\n2175\n2176\n2177\n2178\n2179\n2180\n2181\n2182\n2183\n2184\n2185\n2186\n2187\n2188\n2189\n2190\n2191\n2192\n2193\n2194\n2195\n2196\n2197\n2198\n2199\n2200\n2201\n2202\n2203\n2204\n2205\n2206\n2207\n2208\n2209\n2210\n2211\n2212\n2213\n2214\n2215\n2216\n2217\n2218\n2219\n2220\n2221\n2222\n2223\n2224\n2225\n2226\n2227\n2228\n2229\n2230\n2231\n2232\n2233\n2234\n2235\n2236\n2237\n2238\n2239\n2240\n2241\n2242\n2243\n2244\n2245\n2246\n2247\n2248\n2249\n2250\n2251\n2252\n2253\n2254\n2255\n2256\n2257\n2258\n2259\n2260\n2261\n2262\n2263\n2264\n2265\n2266\n2267\n2268\n2269\n2270\n2271\n2272\n2273\n2274\n2275\n2276\n2277\n2278\n2279\n2280\n2281\n2282\n2283\n2284\n2285\n2286\n2287\n2288\n2289\n2290\n2291\n2292\n2293\n2294\n2295\n2296\n2297\n2298\n2299\n2300\n2301\n2302\n2303\n2304\n2305\n2306\n2307\n2308\n2309\n2310\n2311\n2312\n2313\n2314\n2315\n2316\n2317\n2318\n2319\n2320\n2321\n2322\n2323\n2324\n2325\n2326\n2327\n2328\n2329\n2330\n2331\n2332\n2333\n2334\n2335\n2336\n2337\n2338\n2339\n2340\n2341\n2342\n2343\n2344\n2345\n2346\n2347\n2348\n2349\n2350\n2351\n2352\n2353\n2354\n2355\n2356\n2357\n2358\n2359\n2360\n2361\n2362\n2363\n2364\n2365\n2366\n2367\n2368\n2369\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\nlabels = labels.astype(int)\nf1_scores = {}\naccuracy_scores = {}\nprecision_scores = {}\nrecall_scores = {}\nunique_categories = np.unique(categories)  # Ensure this matches the category data type returned\n\nfor category in unique_categories:\n    category_mask = (categories == category)\n    cat_labels = labels[category_mask]\n    cat_predictions = predictions[category_mask]  # Use predictions here, not logits\n\n    # Ensure that the shape of cat_labels and cat_predictions is one-dimensional\n#     cat_labels = np.squeeze(cat_labels)\n#     cat_predictions = np.squeeze(cat_predictions)\n\n    # Calculate F1 score, accuracy, precision, and recall for the category\n    f1 = f1_score(cat_labels, cat_predictions, average='macro')\n    acc = accuracy_score(cat_labels, cat_predictions)\n    precision = precision_score(cat_labels, cat_predictions, average='macro')\n    recall = recall_score(cat_labels, cat_predictions, average='macro')\n\n    f1_scores[category] = f1\n    accuracy_scores[category] = acc\n    precision_scores[category] = precision\n    recall_scores[category] = recall\n\n# Print scores for each category\navg_f1 = 0\navg_acc = 0\navg_precision = 0\navg_recall = 0\n\nfor category in unique_categories:\n    print(f\"Metrics for {category}:\")\n    print(f\"  F1 Score: {f1_scores[category]:.4f}\")\n    print(f\"  Accuracy: {accuracy_scores[category]:.4f}\")\n    print(f\"  Precision: {precision_scores[category]:.4f}\")\n    print(f\"  Recall: {recall_scores[category]:.4f}\")\n    \n    avg_f1 += f1_scores[category]\n    avg_acc += accuracy_scores[category]\n    avg_precision += precision_scores[category]\n    avg_recall += recall_scores[category]\n\n# Calculate and print average scores\nnum_categories = len(unique_categories)\navg_f1 /= num_categories\navg_acc /= num_categories\navg_precision /= num_categories\navg_recall /= num_categories\n\nprint(f\"Average F1 Score: {avg_f1:.4f}\")\nprint(f\"Average Accuracy: {avg_acc:.4f}\")\nprint(f\"Average Precision: {avg_precision:.4f}\")\nprint(f\"Average Recall: {avg_recall:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:41:28.967997Z","iopub.execute_input":"2024-04-25T14:41:28.968708Z","iopub.status.idle":"2024-04-25T14:41:29.094651Z","shell.execute_reply.started":"2024-04-25T14:41:28.968672Z","shell.execute_reply":"2024-04-25T14:41:29.093646Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Metrics for Achievement:\n  F1 Score: 0.7155\n  Accuracy: 0.7342\n  Precision: 0.7138\n  Recall: 0.7493\nMetrics for Benevolence: caring:\n  F1 Score: 0.4395\n  Accuracy: 0.4557\n  Precision: 0.6228\n  Recall: 0.5757\nMetrics for Benevolence: dependability:\n  F1 Score: 0.4540\n  Accuracy: 0.5243\n  Precision: 0.5243\n  Recall: 0.5500\nMetrics for Conformity: interpersonal:\n  F1 Score: 0.5966\n  Accuracy: 0.9509\n  Precision: 0.5974\n  Recall: 0.5958\nMetrics for Conformity: rules:\n  F1 Score: 0.4519\n  Accuracy: 0.4525\n  Precision: 0.5892\n  Recall: 0.5970\nMetrics for Face:\n  F1 Score: 0.5330\n  Accuracy: 0.9151\n  Precision: 0.5655\n  Recall: 0.5269\nMetrics for Hedonism:\n  F1 Score: 0.6983\n  Accuracy: 0.9420\n  Precision: 0.7132\n  Recall: 0.6856\nMetrics for Humility:\n  F1 Score: 0.5186\n  Accuracy: 0.8792\n  Precision: 0.5185\n  Recall: 0.5187\nMetrics for Power: dominance:\n  F1 Score: 0.6273\n  Accuracy: 0.8618\n  Precision: 0.6129\n  Recall: 0.6511\nMetrics for Power: resources:\n  F1 Score: 0.7003\n  Accuracy: 0.8829\n  Precision: 0.6599\n  Recall: 0.8144\nMetrics for Security: personal:\n  F1 Score: 0.5565\n  Accuracy: 0.5733\n  Precision: 0.7020\n  Recall: 0.6374\nMetrics for Security: societal:\n  F1 Score: 0.5260\n  Accuracy: 0.5295\n  Precision: 0.6167\n  Recall: 0.6377\nMetrics for Self-direction: action:\n  F1 Score: 0.5895\n  Accuracy: 0.6055\n  Precision: 0.6260\n  Recall: 0.6619\nMetrics for Self-direction: thought:\n  F1 Score: 0.6343\n  Accuracy: 0.7574\n  Precision: 0.6234\n  Recall: 0.7201\nMetrics for Stimulation:\n  F1 Score: 0.6471\n  Accuracy: 0.9262\n  Precision: 0.7148\n  Recall: 0.6163\nMetrics for Tradition:\n  F1 Score: 0.6652\n  Accuracy: 0.8613\n  Precision: 0.6417\n  Recall: 0.7118\nMetrics for Universalism: concern:\n  F1 Score: 0.4466\n  Accuracy: 0.4773\n  Precision: 0.6812\n  Recall: 0.5867\nMetrics for Universalism: nature:\n  F1 Score: 0.8087\n  Accuracy: 0.9525\n  Precision: 0.8110\n  Recall: 0.8065\nMetrics for Universalism: objectivity:\n  F1 Score: 0.5112\n  Accuracy: 0.5322\n  Precision: 0.5948\n  Recall: 0.6449\nMetrics for Universalism: tolerance:\n  F1 Score: 0.5815\n  Accuracy: 0.7991\n  Precision: 0.5741\n  Recall: 0.5966\nAverage F1 Score: 0.5851\nAverage Accuracy: 0.7306\nAverage Precision: 0.6351\nAverage Recall: 0.6442\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load the arguments data (assuming it has columns 'id', 'premise')\narguments_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/arguments-test.tsv', delimiter='\\t')\n\n# Load the value labels data (assuming it has columns 'id', 'value_label')\nlabels_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/labels-test.tsv', delimiter='\\t')\n\n# Load the value descriptions from a JSON file\nwith open('/kaggle/input/value-categories-2/value-categories.json', 'r') as file:\n    value_descriptions = json.load(file)\n    \nlabels_long_df = labels_df.melt(id_vars='Argument ID', var_name='value_category', value_name='label')\nlabels_long_df['label'] = labels_long_df['label'].replace({0: 2, 1: 0})\n# labels_long_df = labels_long_df[labels_long_df['value_category'] != 'Universalism: objectivity']\nlabels_long_df['value_description'] = labels_long_df['value_category'].apply(lambda x: value_descriptions[x.lower().replace(\": \",\"-\")]['personal-motivation'])\ncombined_df_test = pd.merge(arguments_df, labels_long_df, left_on='Argument ID', right_on='Argument ID')\ncombined_df_test['Argument'] = combined_df_test.apply(\n    lambda row: f\"{row['Stance']} {row['Conclusion']} by saying {row['Premise']}\",\n    axis=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:42:00.480388Z","iopub.execute_input":"2024-04-25T14:42:00.480734Z","iopub.status.idle":"2024-04-25T14:42:01.155020Z","shell.execute_reply.started":"2024-04-25T14:42:00.480710Z","shell.execute_reply":"2024-04-25T14:42:01.154233Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"test_inputs = tokenizer(list(combined_df_test['Argument']), list(combined_df_test['value_description']), padding=True, truncation=True, return_tensors=\"pt\")\ntest_input_ids = test_inputs['input_ids'].to(device)\ntest_attention_mask = test_inputs['attention_mask'].to(device)\ntest_labels = torch.tensor(combined_df_test['label'].values).to(device)\n\ntest_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\ntest_dataloader = DataLoader(test_dataset, batch_size=16)\n\n# Function to evaluate the model on the test set\ndef evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [b.to(device) for b in batch]\n\n            outputs = model(b_input_ids, attention_mask=b_attention_mask)\n            logits = outputs.logits\n\n            logits = logits.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n\n            batch_predictions = np.argmax(logits, axis=1)\n            predictions.extend(batch_predictions)\n            true_labels.extend(label_ids)\n\n    return predictions, true_labels\n\n# Evaluate the model\n# predictions, true_labels = evaluate_model(model, test_dataloader)\n\n# # Calculate accuracy and F1 score\n# accuracy = accuracy_score(true_labels, predictions)\n# f1 = f1_score(true_labels, predictions, average='binary')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:42:18.324114Z","iopub.execute_input":"2024-04-25T14:42:18.324453Z","iopub.status.idle":"2024-04-25T14:42:32.215949Z","shell.execute_reply.started":"2024-04-25T14:42:18.324429Z","shell.execute_reply":"2024-04-25T14:42:32.214932Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset,DataLoader\nprint(1)\nclass CategoryDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=512):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data.iloc[idx]\n        premise = item['Argument']\n        description = item['value_description']\n        label = item['label']\n        category = item['value_category']\n        \n        # Tokenize the text pair\n        encoding = self.tokenizer(premise, description, add_special_tokens=True, \n                                  max_length=self.max_len, padding='max_length', \n                                  truncation=True, return_tensors=\"pt\")\n        \n        input_ids = encoding['input_ids'].squeeze(0)  # Remove the batch dimension\n        attention_mask = encoding['attention_mask'].squeeze(0)\n        \n        return input_ids, attention_mask, torch.tensor(label, dtype=torch.float), category\n    \ndataset = CategoryDataset(combined_df_test,tokenizer)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n\ndef evaluate_model(model, dataloader, device):\n    model.eval()\n    all_logits = []\n    all_labels = []\n    all_categories = []\n    all_predictions = []\n    print(len(dataloader))\n\n    with torch.no_grad():\n        for (j,(input_ids, attention_mask, labels, categories)) in enumerate(dataloader):\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n\n            # Calculate probabilities using softmax for multi-class\n            probabilities = torch.softmax(logits, dim=1)\n            predictions = torch.argmax(probabilities, dim=1)  # Initial predictions\n\n            # Adjust predictions where class '1' should be ignored\n            for i, pred in enumerate(predictions):\n                if pred == 1:\n                    # Get probabilities for classes 0 and 2\n                    prob_0 = probabilities[i, 0]\n                    prob_2 = probabilities[i, 2]\n                    # Choose the class (either 0 or 2) with the highest probability excluding class 1\n                    predictions[i] = 0 if prob_0 > prob_2 else 2\n\n            # Store the results\n            all_logits.append(logits.cpu())\n            all_labels.append(labels.cpu())\n            all_predictions.append(predictions.cpu())\n            all_categories.append(categories)  # Assuming categories can be batched directly\n            if(j%100==0):\n                print(j)\n\n    # Concatenate results from all batches\n    all_logits = torch.cat(all_logits).numpy()\n    all_labels = torch.cat(all_labels).numpy()\n    all_predictions = torch.cat(all_predictions).numpy()\n    all_categories = np.concatenate(all_categories)\n\n    return all_logits, all_labels, all_predictions, all_categories\n\n# Get the predictions, true labels, and categories from the evaluation\nlogits, labels, predictions, categories = evaluate_model(model, dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T15:02:19.030320Z","iopub.execute_input":"2024-04-25T15:02:19.031166Z","iopub.status.idle":"2024-04-25T15:17:55.906756Z","shell.execute_reply.started":"2024-04-25T15:02:19.031133Z","shell.execute_reply":"2024-04-25T15:17:55.905734Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"1\n1970\n0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\nlabels = labels.astype(int)\nf1_scores = {}\naccuracy_scores = {}\nprecision_scores = {}\nrecall_scores = {}\nunique_categories = np.unique(categories)  # Ensure this matches the category data type returned\n\nfor category in unique_categories:\n    category_mask = (categories == category)\n    cat_labels = labels[category_mask]\n    cat_predictions = predictions[category_mask]  # Use predictions here, not logits\n\n    # Ensure that the shape of cat_labels and cat_predictions is one-dimensional\n#     cat_labels = np.squeeze(cat_labels)\n#     cat_predictions = np.squeeze(cat_predictions)\n\n    # Calculate F1 score, accuracy, precision, and recall for the category\n    f1 = f1_score(cat_labels, cat_predictions, average='macro')\n    acc = accuracy_score(cat_labels, cat_predictions)\n    precision = precision_score(cat_labels, cat_predictions, average='macro')\n    recall = recall_score(cat_labels, cat_predictions, average='macro')\n\n    f1_scores[category] = f1\n    accuracy_scores[category] = acc\n    precision_scores[category] = precision\n    recall_scores[category] = recall\n\n# Print scores for each category\navg_f1 = 0\navg_acc = 0\navg_precision = 0\navg_recall = 0\n\nfor category in unique_categories:\n    print(f\"Metrics for {category}:\")\n    print(f\"  F1 Score: {f1_scores[category]:.4f}\")\n    print(f\"  Accuracy: {accuracy_scores[category]:.4f}\")\n    print(f\"  Precision: {precision_scores[category]:.4f}\")\n    print(f\"  Recall: {recall_scores[category]:.4f}\")\n    \n    avg_f1 += f1_scores[category]\n    avg_acc += accuracy_scores[category]\n    avg_precision += precision_scores[category]\n    avg_recall += recall_scores[category]\n\n# Calculate and print average scores\nnum_categories = len(unique_categories)\navg_f1 /= num_categories\navg_acc /= num_categories\navg_precision /= num_categories\navg_recall /= num_categories\nprint(num_categories)\n\nprint(f\"Average F1 Score: {avg_f1:.4f}\")\nprint(f\"Average Accuracy: {avg_acc:.4f}\")\nprint(f\"Average Precision: {avg_precision:.4f}\")\nprint(f\"Average Recall: {avg_recall:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T15:19:14.974802Z","iopub.execute_input":"2024-04-25T15:19:14.975598Z","iopub.status.idle":"2024-04-25T15:19:15.100497Z","shell.execute_reply.started":"2024-04-25T15:19:14.975569Z","shell.execute_reply":"2024-04-25T15:19:15.099515Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Metrics for Achievement:\n  F1 Score: 0.6690\n  Accuracy: 0.7246\n  Precision: 0.6619\n  Recall: 0.6850\nMetrics for Benevolence: caring:\n  F1 Score: 0.4023\n  Accuracy: 0.4023\n  Precision: 0.5980\n  Recall: 0.5985\nMetrics for Benevolence: dependability:\n  F1 Score: 0.5263\n  Accuracy: 0.6567\n  Precision: 0.5589\n  Recall: 0.6485\nMetrics for Conformity: interpersonal:\n  F1 Score: 0.5546\n  Accuracy: 0.9651\n  Precision: 0.6844\n  Recall: 0.5358\nMetrics for Conformity: rules:\n  F1 Score: 0.3936\n  Accuracy: 0.3947\n  Precision: 0.6009\n  Recall: 0.6178\nMetrics for Face:\n  F1 Score: 0.5245\n  Accuracy: 0.9143\n  Precision: 0.5368\n  Recall: 0.5209\nMetrics for Hedonism:\n  F1 Score: 0.6029\n  Accuracy: 0.9772\n  Precision: 0.6183\n  Recall: 0.5913\nMetrics for Humility:\n  F1 Score: 0.5176\n  Accuracy: 0.9327\n  Precision: 0.5272\n  Recall: 0.5150\nMetrics for Power: dominance:\n  F1 Score: 0.5978\n  Accuracy: 0.8610\n  Precision: 0.5820\n  Recall: 0.6380\nMetrics for Power: resources:\n  F1 Score: 0.7146\n  Accuracy: 0.9023\n  Precision: 0.6746\n  Recall: 0.8017\nMetrics for Security: personal:\n  F1 Score: 0.6516\n  Accuracy: 0.6516\n  Precision: 0.7274\n  Recall: 0.7264\nMetrics for Security: societal:\n  F1 Score: 0.4488\n  Accuracy: 0.4492\n  Precision: 0.6254\n  Recall: 0.6152\nMetrics for Self-direction: action:\n  F1 Score: 0.5598\n  Accuracy: 0.5704\n  Precision: 0.6236\n  Recall: 0.6595\nMetrics for Self-direction: thought:\n  F1 Score: 0.6346\n  Accuracy: 0.8268\n  Precision: 0.6134\n  Recall: 0.7064\nMetrics for Stimulation:\n  F1 Score: 0.5213\n  Accuracy: 0.9486\n  Precision: 0.6264\n  Recall: 0.5171\nMetrics for Tradition:\n  F1 Score: 0.6386\n  Accuracy: 0.7602\n  Precision: 0.6317\n  Recall: 0.7976\nMetrics for Universalism: concern:\n  F1 Score: 0.4173\n  Accuracy: 0.4619\n  Precision: 0.6846\n  Recall: 0.5688\nMetrics for Universalism: nature:\n  F1 Score: 0.8582\n  Accuracy: 0.9556\n  Precision: 0.8817\n  Recall: 0.8381\nMetrics for Universalism: objectivity:\n  F1 Score: 0.5814\n  Accuracy: 0.5971\n  Precision: 0.6002\n  Recall: 0.6195\nMetrics for Universalism: tolerance:\n  F1 Score: 0.5487\n  Accuracy: 0.6694\n  Precision: 0.5689\n  Recall: 0.6462\n20\nAverage F1 Score: 0.5682\nAverage Accuracy: 0.7311\nAverage Precision: 0.6313\nAverage Recall: 0.6424\n","output_type":"stream"}]}]}