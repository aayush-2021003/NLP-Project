{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8194132,"sourceType":"datasetVersion","datasetId":4853226},{"sourceId":8194151,"sourceType":"datasetVersion","datasetId":4853242}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-23T14:46:35.558910Z","iopub.execute_input":"2024-04-23T14:46:35.560019Z","iopub.status.idle":"2024-04-23T14:46:35.958098Z","shell.execute_reply.started":"2024-04-23T14:46:35.559982Z","shell.execute_reply":"2024-04-23T14:46:35.957087Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/projectvalues/Project_Data/labels-test.tsv\n/kaggle/input/projectvalues/Project_Data/arguments-validation.tsv\n/kaggle/input/projectvalues/Project_Data/arguments-training.tsv\n/kaggle/input/projectvalues/Project_Data/README.md\n/kaggle/input/projectvalues/Project_Data/arguments-test.tsv\n/kaggle/input/projectvalues/Project_Data/labels-validation.tsv\n/kaggle/input/projectvalues/Project_Data/labels-training.tsv\n/kaggle/input/value-categories/value-categories (1).json\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load the arguments data (assuming it has columns 'id', 'premise')\narguments_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/arguments-training.tsv', delimiter='\\t')\n\n# Load the value labels data (assuming it has columns 'id', 'value_label')\nlabels_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/labels-training.tsv', delimiter='\\t')\n\n# Load the value descriptions from a JSON file\nwith open('/kaggle/input/value-categories/value-categories (1).json', 'r') as file:\n    value_descriptions = json.load(file)\n    \nlabels_long_df = labels_df.melt(id_vars='Argument ID', var_name='value_category', value_name='label')\nlabels_long_df = labels_long_df[labels_long_df['value_category'] != 'Universalism: objectivity']\nlabels_long_df['value_description'] = labels_long_df['value_category'].apply(lambda x: value_descriptions[x.lower().replace(\": \",\"-\")]['personal-motivation'])\ncombined_df = pd.merge(arguments_df, labels_long_df, left_on='Argument ID', right_on='Argument ID')\ncombined_df['Argument'] = combined_df.apply(\n    lambda row: f\"{row['Stance']} {row['Conclusion']} by saying {row['Premise']}\",\n    axis=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T14:46:35.960217Z","iopub.execute_input":"2024-04-23T14:46:35.960947Z","iopub.status.idle":"2024-04-23T14:46:38.352774Z","shell.execute_reply.started":"2024-04-23T14:46:35.960912Z","shell.execute_reply":"2024-04-23T14:46:38.351827Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"final_df=combined_df\ndf_majority = final_df[final_df.label == 0]\ndf_minority = final_df[final_df.label == 1]\n\n# Determine the number of instances you want to keep from the majority class\n# For example, you might want to have a 1:1 ratio\nnumber_of_instances = len(df_minority)\n\n# Downsample the majority class\ndf_majority_downsampled = df_majority.sample(n=number_of_instances)\n\n# Combine the downsampled majority class with the minority class to get a balanced dataset\nbalanced_df = pd.concat([df_majority_downsampled, df_minority])\n\n# Shuffle the dataset to mix the two classes well\nbalanced_df = balanced_df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T14:46:38.354080Z","iopub.execute_input":"2024-04-23T14:46:38.354714Z","iopub.status.idle":"2024-04-23T14:46:38.406869Z","shell.execute_reply.started":"2024-04-23T14:46:38.354679Z","shell.execute_reply":"2024-04-23T14:46:38.406052Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"balanced_df","metadata":{"execution":{"iopub.status.busy":"2024-04-23T14:46:38.409292Z","iopub.execute_input":"2024-04-23T14:46:38.409983Z","iopub.status.idle":"2024-04-23T14:46:38.430815Z","shell.execute_reply.started":"2024-04-23T14:46:38.409935Z","shell.execute_reply":"2024-04-23T14:46:38.429789Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      Argument ID                                         Conclusion  \\\n0          A19165                        We should ban telemarketing   \n1          A01006        We should end the use of economic sanctions   \n2          A21166        We should end the use of economic sanctions   \n3          A30066  We should fight for the abolition of nuclear w...   \n4          A22123                        We should ban telemarketing   \n...           ...                                                ...   \n34627      A18099     We should abolish intellectual property rights   \n34628      A30263  We should abolish the right to keep and bear arms   \n34629      A27491                   We should legalize sex selection   \n34630      D01096  We should subsidize higher education institutions   \n34631      D01053  India should store the data within the territo...   \n\n            Stance                                            Premise  \\\n0          against  telemarketing is a perfectly valid marketing a...   \n1          against  sometimes economic sanctions are the only thin...   \n2      in favor of  we could not support economic sanctions as it ...   \n3          against  nuclear weapons should be retained as they act...   \n4      in favor of  telemarketing intrudes on the personal lives o...   \n...            ...                                                ...   \n34627  in favor of  maintaining intellectual property rights for a...   \n34628      against  the freedom to bear arms has always been a bas...   \n34629  in favor of  people can have strong feelings about which se...   \n34630  in favor of  Indian students perform brilliantly when they ...   \n34631  in favor of  Data localization laws result in the setting u...   \n\n               value_category  label  \\\n0      Self-direction: action      1   \n1          Security: societal      1   \n2          Security: societal      1   \n3      Self-direction: action      0   \n4          Security: personal      1   \n...                       ...    ...   \n34627        Power: resources      1   \n34628   Universalism: concern      0   \n34629                Hedonism      0   \n34630               Tradition      0   \n34631             Stimulation      0   \n\n                                       value_description  \\\n0      It is important to make own decisions about li...   \n1      Country should protect itself against all thre...   \n2      Country should protect itself against all thre...   \n3      It is important to make own decisions about li...   \n4      Avoid dangerous situations, value personal sec...   \n...                                                  ...   \n34627  Having lots of money for the power it brings, ...   \n34628  Protecting the weak and vulnerable, care about...   \n34629  Having a good time, enjoying lifeâ€™s pleasures ...   \n34630  Maintain traditional beliefs and values, follo...   \n34631  Always looking for something new to do, doing ...   \n\n                                                Argument  \n0      against We should ban telemarketing by saying ...  \n1      against We should end the use of economic sanc...  \n2      in favor of We should end the use of economic ...  \n3      against We should fight for the abolition of n...  \n4      in favor of We should ban telemarketing by say...  \n...                                                  ...  \n34627  in favor of We should abolish intellectual pro...  \n34628  against We should abolish the right to keep an...  \n34629  in favor of We should legalize sex selection b...  \n34630  in favor of We should subsidize higher educati...  \n34631  in favor of India should store the data within...  \n\n[34632 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Argument ID</th>\n      <th>Conclusion</th>\n      <th>Stance</th>\n      <th>Premise</th>\n      <th>value_category</th>\n      <th>label</th>\n      <th>value_description</th>\n      <th>Argument</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A19165</td>\n      <td>We should ban telemarketing</td>\n      <td>against</td>\n      <td>telemarketing is a perfectly valid marketing a...</td>\n      <td>Self-direction: action</td>\n      <td>1</td>\n      <td>It is important to make own decisions about li...</td>\n      <td>against We should ban telemarketing by saying ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A01006</td>\n      <td>We should end the use of economic sanctions</td>\n      <td>against</td>\n      <td>sometimes economic sanctions are the only thin...</td>\n      <td>Security: societal</td>\n      <td>1</td>\n      <td>Country should protect itself against all thre...</td>\n      <td>against We should end the use of economic sanc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A21166</td>\n      <td>We should end the use of economic sanctions</td>\n      <td>in favor of</td>\n      <td>we could not support economic sanctions as it ...</td>\n      <td>Security: societal</td>\n      <td>1</td>\n      <td>Country should protect itself against all thre...</td>\n      <td>in favor of We should end the use of economic ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A30066</td>\n      <td>We should fight for the abolition of nuclear w...</td>\n      <td>against</td>\n      <td>nuclear weapons should be retained as they act...</td>\n      <td>Self-direction: action</td>\n      <td>0</td>\n      <td>It is important to make own decisions about li...</td>\n      <td>against We should fight for the abolition of n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A22123</td>\n      <td>We should ban telemarketing</td>\n      <td>in favor of</td>\n      <td>telemarketing intrudes on the personal lives o...</td>\n      <td>Security: personal</td>\n      <td>1</td>\n      <td>Avoid dangerous situations, value personal sec...</td>\n      <td>in favor of We should ban telemarketing by say...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34627</th>\n      <td>A18099</td>\n      <td>We should abolish intellectual property rights</td>\n      <td>in favor of</td>\n      <td>maintaining intellectual property rights for a...</td>\n      <td>Power: resources</td>\n      <td>1</td>\n      <td>Having lots of money for the power it brings, ...</td>\n      <td>in favor of We should abolish intellectual pro...</td>\n    </tr>\n    <tr>\n      <th>34628</th>\n      <td>A30263</td>\n      <td>We should abolish the right to keep and bear arms</td>\n      <td>against</td>\n      <td>the freedom to bear arms has always been a bas...</td>\n      <td>Universalism: concern</td>\n      <td>0</td>\n      <td>Protecting the weak and vulnerable, care about...</td>\n      <td>against We should abolish the right to keep an...</td>\n    </tr>\n    <tr>\n      <th>34629</th>\n      <td>A27491</td>\n      <td>We should legalize sex selection</td>\n      <td>in favor of</td>\n      <td>people can have strong feelings about which se...</td>\n      <td>Hedonism</td>\n      <td>0</td>\n      <td>Having a good time, enjoying lifeâ€™s pleasures ...</td>\n      <td>in favor of We should legalize sex selection b...</td>\n    </tr>\n    <tr>\n      <th>34630</th>\n      <td>D01096</td>\n      <td>We should subsidize higher education institutions</td>\n      <td>in favor of</td>\n      <td>Indian students perform brilliantly when they ...</td>\n      <td>Tradition</td>\n      <td>0</td>\n      <td>Maintain traditional beliefs and values, follo...</td>\n      <td>in favor of We should subsidize higher educati...</td>\n    </tr>\n    <tr>\n      <th>34631</th>\n      <td>D01053</td>\n      <td>India should store the data within the territo...</td>\n      <td>in favor of</td>\n      <td>Data localization laws result in the setting u...</td>\n      <td>Stimulation</td>\n      <td>0</td>\n      <td>Always looking for something new to do, doing ...</td>\n      <td>in favor of India should store the data within...</td>\n    </tr>\n  </tbody>\n</table>\n<p>34632 rows Ã— 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset, random_split\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom torch.nn.functional import cross_entropy\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport torch\nfrom sklearn.metrics import accuracy_score,f1_score\nmodel_name = 'pepa/roberta-base-snli'\nconfig = AutoModelForSequenceClassification.from_pretrained(model_name, \n                                                             return_dict=True,\n                                                             output_hidden_states=False,\n                                                             hidden_dropout_prob=0.3,  # Set dropout probability for hidden layers\n                                                             attention_probs_dropout_prob=0.3)  # Set dropout probability for attention layers\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel=model.to(device)\ninputs = tokenizer(list(balanced_df['Argument']), list(balanced_df['value_description']), padding=True, truncation=True, return_tensors=\"pt\")\ninput_ids = inputs['input_ids']\nattention_mask = inputs['attention_mask']\nlabels = torch.tensor(balanced_df['label'].values)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T14:46:38.431863Z","iopub.execute_input":"2024-04-23T14:46:38.432188Z","iopub.status.idle":"2024-04-23T14:47:11.203312Z","shell.execute_reply.started":"2024-04-23T14:46:38.432161Z","shell.execute_reply":"2024-04-23T14:47:11.201746Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/915 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc4f4d42740a4d7faa2edf11bbdedc32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c4de8cd38c43f5ada73f2be3ba82b4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4e616cc1ae474b9bd189d0878b2bb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45855862ced44b4ca042e53a04bbdd2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90de822c08be486b82efad406d343ea9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de206c231014c22be1015c90c8fabf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c05feb7813f4b62ba7ab16a80b43a46"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = TensorDataset(input_ids, attention_mask, labels)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\noptimizer = AdamW(model.parameters(), lr=2e-5)\nepochs=3\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\nimport numpy as np\n# Define a training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    predictions = []\n    true_labels = []\n    steps=1\n    i=0\n    for batch in train_dataloader:\n        b_input_ids, b_attention_mask, b_labels = batch\n        b_input_ids = b_input_ids.to(device)\n        b_attention_mask = b_attention_mask.to(device)\n        b_labels = b_labels.to(device)\n        \n        # Clear any previously calculated gradients\n        optimizer.zero_grad()\n        \n        # Perform a forward pass. This will return logits.\n        outputs = model(b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n        \n        # Calculate loss using the outputs and the labels\n        loss = outputs[0]\n        total_loss += loss.item()\n        logits = outputs.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        predictions.extend(np.argmax(logits, axis=1).flatten())\n        true_labels.extend(label_ids.flatten())\n        \n        # Perform a backward pass to calculate gradients\n        loss.backward()\n        \n        # Update parameters and take a step using the computed gradient\n        optimizer.step()\n        \n        # Update the learning rate\n        scheduler.step()\n        if steps % 200 == 0:\n            interim_f1 = f1_score(true_labels, predictions, average='macro')\n            print(f\"Epoch {epoch}, Step {steps}, Loss: {total_loss / steps:.4f}, Interim F1 Score: {interim_f1:.4f}\")\n            predictions = []  # Reset predictions\n            true_labels = []  # Reset true labels\n        steps+=1\n    \n    # Calculate the average loss over the training data\n    avg_train_loss = total_loss / len(train_dataloader)\n\n\nprint(\"Training complete\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T14:47:11.204679Z","iopub.execute_input":"2024-04-23T14:47:11.205616Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load the arguments data (assuming it has columns 'id', 'premise')\narguments_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/arguments-validation.tsv', delimiter='\\t')\n\n# Load the value labels data (assuming it has columns 'id', 'value_label')\nlabels_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/labels-validation.tsv', delimiter='\\t')\n\n# Load the value descriptions from a JSON file\nwith open('/kaggle/input/value-categories/value-categories (1).json', 'r') as file:\n    value_descriptions = json.load(file)\n    \nlabels_long_df = labels_df.melt(id_vars='Argument ID', var_name='value_category', value_name='label')\nlabels_long_df = labels_long_df[labels_long_df['value_category'] != 'Universalism: objectivity']\nlabels_long_df['value_description'] = labels_long_df['value_category'].apply(lambda x: value_descriptions[x.lower().replace(\": \",\"-\")]['personal-motivation'])\ncombined_df_val = pd.merge(arguments_df, labels_long_df, left_on='Argument ID', right_on='Argument ID')\ncombined_df_val['Argument'] = combined_df_val.apply(\n    lambda row: f\"{row['Stance']} {row['Conclusion']} by saying {row['Premise']}\",\n    axis=1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_inputs = tokenizer(list(combined_df_val['Argument']), list(combined_df_val['value_description']), padding=True, truncation=True, return_tensors=\"pt\")\ntest_input_ids = test_inputs['input_ids'].to(device)\ntest_attention_mask = test_inputs['attention_mask'].to(device)\ntest_labels = torch.tensor(combined_df_val['label'].values).to(device)\n\ntest_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\ntest_dataloader = DataLoader(test_dataset, batch_size=16)\n\n# Function to evaluate the model on the test set\ndef evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [b.to(device) for b in batch]\n\n            outputs = model(b_input_ids, attention_mask=b_attention_mask)\n            logits = outputs.logits\n\n            logits = logits.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n\n            batch_predictions = np.argmax(logits, axis=1)\n            predictions.extend(batch_predictions)\n            true_labels.extend(label_ids)\n\n    return predictions, true_labels\n\n# Evaluate the model\n# predictions, true_labels = evaluate_model(model, test_dataloader)\n\n# # Calculate accuracy and F1 score\n# accuracy = accuracy_score(true_labels, predictions)\n# f1 = f1_score(true_labels, predictions, average='binary')\n\n# print(f\"Test Accuracy: {accuracy:.4f}\")\n# print(f\"Test F1 Score: {f1:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset,DataLoader\nprint(1)\nclass CategoryDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=512):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data.iloc[idx]\n        premise = item['Argument']\n        description = item['value_description']\n        label = item['label']\n        category = item['value_category']\n        \n        # Tokenize the text pair\n        encoding = self.tokenizer(premise, description, add_special_tokens=True, \n                                  max_length=self.max_len, padding='max_length', \n                                  truncation=True, return_tensors=\"pt\")\n        \n        input_ids = encoding['input_ids'].squeeze(0)  # Remove the batch dimension\n        attention_mask = encoding['attention_mask'].squeeze(0)\n        \n        return input_ids, attention_mask, torch.tensor(label, dtype=torch.float), category\n    \ndataset = CategoryDataset(combined_df_val,tokenizer)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n\ndef evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    all_logits = []\n    all_labels = []\n    all_categories = []\n\n    with torch.no_grad():\n        for input_ids, attention_mask, labels, categories in dataloader:\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits  # Using sigmoid for binary classification\n            logits = logits.cpu().numpy()\n            labels = labels.cpu().numpy()\n            all_logits.extend(np.argmax(logits, axis=1))\n            all_labels.extend(labels)\n            all_categories.extend(categories)\n\n\n    # Convert lists to numpy arrays\n    all_logits = np.array(all_logits)\n    all_labels = np.array(all_labels)\n    all_categories = np.array(all_categories)\n\n    return all_logits, all_labels, all_categories\n\n# Get the predictions, true labels, and categories from the evaluation\nlogits, labels, categories = evaluate_model(model, dataloader)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores = {}\nunique_categories = np.unique(categories)\n\nfor category in unique_categories:\n    category_mask = (categories == category)\n    cat_labels = labels[category_mask]\n    cat_logits = logits[category_mask]\n#     print(cat_labels.shape)\n#     print(cat_logits.shape)\n    # Ensure that the shape of cat_labels and cat_logits is one-dimensional\n    cat_labels = np.squeeze(cat_labels)\n    cat_logits = np.squeeze(cat_logits)\n\n    # Calculate F1 score for the category\n    f1 = f1_score(cat_labels, cat_logits, average='binary')\n    f1_scores[category] = f1\n\n# Print F1 scores for each category\navg_score=0\nfor category, score in f1_scores.items():\n    print(f\"F1 Score for {category}: {score:.4f}\")\n    avg_score+=score\navg_score=avg_score/19\nprint(avg_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load the arguments data (assuming it has columns 'id', 'premise')\narguments_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/arguments-test.tsv', delimiter='\\t')\n\n# Load the value labels data (assuming it has columns 'id', 'value_label')\nlabels_df = pd.read_csv('/kaggle/input/projectvalues/Project_Data/labels-test.tsv', delimiter='\\t')\n\n# Load the value descriptions from a JSON file\nwith open('/kaggle/input/value-categories/value-categories (1).json', 'r') as file:\n    value_descriptions = json.load(file)\n    \nlabels_long_df = labels_df.melt(id_vars='Argument ID', var_name='value_category', value_name='label')\nlabels_long_df = labels_long_df[labels_long_df['value_category'] != 'Universalism: objectivity']\nlabels_long_df['value_description'] = labels_long_df['value_category'].apply(lambda x: value_descriptions[x.lower().replace(\": \",\"-\")]['personal-motivation'])\ncombined_df_test = pd.merge(arguments_df, labels_long_df, left_on='Argument ID', right_on='Argument ID')\ncombined_df_test['Argument'] = combined_df_test.apply(\n    lambda row: f\"{row['Stance']} {row['Conclusion']} by saying {row['Premise']}\",\n    axis=1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_inputs = tokenizer(list(combined_df_test['Argument']), list(combined_df_test['value_description']), padding=True, truncation=True, return_tensors=\"pt\")\ntest_input_ids = test_inputs['input_ids'].to(device)\ntest_attention_mask = test_inputs['attention_mask'].to(device)\ntest_labels = torch.tensor(combined_df_test['label'].values).to(device)\n\ntest_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\ntest_dataloader = DataLoader(test_dataset, batch_size=16)\n\n# Function to evaluate the model on the test set\ndef evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [b.to(device) for b in batch]\n\n            outputs = model(b_input_ids, attention_mask=b_attention_mask)\n            logits = outputs.logits\n\n            logits = logits.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n\n            batch_predictions = np.argmax(logits, axis=1)\n            predictions.extend(batch_predictions)\n            true_labels.extend(label_ids)\n\n    return predictions, true_labels\n\n# Evaluate the model\n# predictions, true_labels = evaluate_model(model, test_dataloader)\n\n# # Calculate accuracy and F1 score\n# accuracy = accuracy_score(true_labels, predictions)\n# f1 = f1_score(true_labels, predictions, average='binary')\n\n# print(f\"Test Accuracy: {accuracy:.4f}\")\n# print(f\"Test F1 Score: {f1:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset,DataLoader\n\nclass CategoryDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=512):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data.iloc[idx]\n        premise = item['Argument']\n        description = item['value_description']\n        label = item['label']\n        category = item['value_category']\n        \n        # Tokenize the text pair\n        encoding = self.tokenizer(premise, description, add_special_tokens=True, \n                                  max_length=self.max_len, padding='max_length', \n                                  truncation=True, return_tensors=\"pt\")\n        \n        input_ids = encoding['input_ids'].squeeze(0)  # Remove the batch dimension\n        attention_mask = encoding['attention_mask'].squeeze(0)\n        \n        return input_ids, attention_mask, torch.tensor(label, dtype=torch.float), category\n    \ndataset = CategoryDataset(combined_df_test,tokenizer)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n\ndef evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    all_logits = []\n    all_labels = []\n    all_categories = []\n\n    with torch.no_grad():\n        for input_ids, attention_mask, labels, categories in dataloader:\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits  # Using sigmoid for binary classification\n            logits = logits.cpu().numpy()\n            labels = labels.cpu().numpy()\n            all_logits.extend(np.argmax(logits, axis=1))\n            all_labels.extend(labels)\n            all_categories.extend(categories)\n\n\n    # Convert lists to numpy arrays\n    all_logits = np.array(all_logits)\n    all_labels = np.array(all_labels)\n    all_categories = np.array(all_categories)\n\n    return all_logits, all_labels, all_categories\n\n# Get the predictions, true labels, and categories from the evaluation\nlogits, labels, categories = evaluate_model(model, dataloader)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores = {}\nunique_categories = np.unique(categories)\n\nfor category in unique_categories:\n    category_mask = (categories == category)\n    cat_labels = labels[category_mask]\n    cat_logits = logits[category_mask]\n#     print(cat_labels.shape)\n#     print(cat_logits.shape)\n    # Ensure that the shape of cat_labels and cat_logits is one-dimensional\n    cat_labels = np.squeeze(cat_labels)\n    cat_logits = np.squeeze(cat_logits)\n\n    # Calculate F1 score for the category\n    f1 = f1_score(cat_labels, cat_logits, average='binary')\n    f1_scores[category] = f1\n\n# Print F1 scores for each category\navg_score=0\nfor category, score in f1_scores.items():\n    print(f\"F1 Score for {category}: {score:.4f}\")\n    avg_score+=score\navg_score=avg_score/19\nprint(avg_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'model_entailment.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}